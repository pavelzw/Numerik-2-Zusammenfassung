\section{Eigenwerte}
\subsection{Grundlagen}

\begin{karte}{Reduzibel}
    Eine Matrix \( A \in \C^{n,n} \) heißt reduzibel, wenn es eine Permutationsmatrix \(P\)
    gibt, sodass 
    \[ P^T A P = B = \left[ \begin{matrix} A_{11} & A_{12} \\ 0 & A_{22} \end{matrix} \right] \]
    mit quadratischen Matrizen \( A_{11} \in \C^{k,k}, A_{22} \in \C^{n-k,n-k} \) gilt. 
    Andernfalls heißt \( A \) irreduzibel.
\end{karte}

\begin{karte}{Reduzibilitätskriterium}
    Seien \( A \in \K^{n,n}, B\in \K^{k,k}, X \in \K^{n,k} \) 
    mit \( \K = \C \) oder \(\K = \R \) und es gelte 
    \[ AX = XB, \rk X = k. \]
    Dann gibt es eine unitäre Matrix \(Q \in \K^{n,n}\) mit 
    \[ Q^H A Q = T = \left[ \begin{matrix}
        T_{11} & T_{12} \\ 0 & T_{22}
    \end{matrix} \right], \]
    wobei \( \lambda(T_{11}) = \lambda(A) \cap \lambda(B) \).
\end{karte}

\subsection{Normalformen}

\begin{karte}{Schur-Normalform}
    Zu jedem \(A\in \C^{n,n}\) gibt es eine unitäre Matrix \(U \in \C^{n,n}\) so, dass 
    \[ U^H A U = R = D + N, \]
    wobei \(R\) obere Dreiecksform, \(N\) strikte obere Dreiecksform hat \\ 
    und \(D = \diag(\lambda_1, \ldots, \lambda_n)\) mit den Eigenwerten \( \lambda_1, \ldots, \lambda_n \)
    von \(A\) ist. Die Matrix \(U\) kann so gewählt werden, dass die Eigenwerte in beliebiger 
    Reihenfolge in \(D\) auftreten.
\end{karte}

\begin{karte}{Reelle Schur-Normalform}
    Zu jedem \( A\in \R^{n,n} \) gibt es eine reelle Orthogonalmatrix \(Q\in \R^{n,n}\), 
    so dass 
    \[ Q^T A Q = R = D + N,\]
    wobei \(R\) eine reelle obere Blockdreiecksmatrix ist, deren Blockdiagonalmatrix \(D\) 
    aus \(1\times 1\) und \(2\times 2\) Blöcken besteht, bei denen alle \(2\times 2\) Blöcke 
    konjugiert komplexe Eigenwerte haben. \(N\) ist eine strikte obere Dreiecksmatrix.
\end{karte}

\begin{karte}{Normale Matrizen}
    Eine Matrix \(A\in \C^{n,n}\) ist normal genau dann, wenn \(A A^H = A^H A\). 

    Eine Matrix \(A\in \C^{n,n}\) ist normal genau dann, wenn sie unitär diagonalisierbar ist, 
    d. h. es gibt eine unitäre Matrix \(U\in \C^{n,n}\), so dass 
    \[ U^H A U = \diag(\lambda_1, \ldots, \lambda_n). \]
\end{karte}

\begin{karte}{Jordan Normalform}
    Zu jedem \( A \in \C^{n,n} \) gibt es eine nicht singuläre Matrix 
    \(X\in \C^{n,n}\), so dass
    \[ X^{-1} A X = J = \diag(J_{m_1}(\lambda_1), \ldots, J_{m_r}(\lambda_r)), \]
    wobei 
    \[ J_{m_i}(\lambda_i) = \left[ \begin{matrix}
        \lambda_i & 1 & & 0 \\
        & \ddots & \ddots & \\
        & & \ddots & 1 \\
        & & & \lambda_i
    \end{matrix} \right] = \lambda_i I + N \in \C^{m_i,m_i}. \]
    Ist \(m_i > 1\), so nennt man \(\lambda_i\) einen Eigenwert 
    mit Defekt und sagt, dass \(A\) Defekt ist.
\end{karte}

\begin{karte}{Spektralradius}
    Sei \(A\in \C^{n,n}\) mit Spektralradius \(\rho = \rho(A) = \max_{\lambda\in\lambda(A)} \abs{\lambda}\) gegeben.
    Bezeichnen wir mit \( ||\cdot || \) eine beliebige \(p\)-Norm, \(1\leq p \leq \infty\), 
    so ist für \(T\in \C^{n,n}\) nicht singulär 
    \[ ||A||_T = ||T^{-1} A T|| \] 
    die zugehörige \(T\)-Norm definiert und es gilt 
    \begin{enumerate}
        \item \(\rho(A)\leq ||A||\).
        \item Ist \(A\) diagonalisierbar, dann gibt es eine nicht singuläre Matrix 
        \(T\), sodass \( ||A||_T = \rho \).
        \item Zu jedem \(\epsilon > 0 \) gibt es eine nicht singuläre Matrix 
        \(T(\epsilon)\), so dass \(||A||_{T(\epsilon)} \leq \rho + \epsilon\).
    \end{enumerate}
\end{karte}

\subsection{Störungstheorie, Einschließung}
\begin{karte}{Bauer-Fike}
    Sei \(A\in \C^{n,n}\) diagonalisierbar, \( X^{-1} A X = D = \diag(\lambda_1, \ldots, \lambda_n) \)
    und sei \( \mu \in \lambda(A+E), E \in \C^{n,n} \). Dann gilt in jeder \(p\)-Norm 
    \[ \min_{1\leq j\leq n} \abs{\mu - \lambda_j} \leq \kappa(X) ||E||. \]
\end{karte}

\begin{karte}{Gershgorin}
    Es gilt 
    \[ \lambda(A) \subseteq \bigcup_{j=1}^n \mathcal{D}_j, 
    \qquad \mathcal{D}_j = \set{t\in \C: \abs{z - a_{jj}}\leq r_j}, 
    \qquad r_j = \sum_{l=1, l\neq j}^n \abs{a_{jl}}. \]
    Wegen \(\lambda(A) = \lambda(A^T)\) kann man den Schnitt der 
    Gershgorin-Kreise von \(A\) und \(A^T\) betrachten.
\end{karte}

\begin{karte}{Eingenwert Fehlerabschätzung}
    Sei \(\lambda \in \lambda(A)\) ein einfacher Eigenwert von \(A\) 
    und seien \(x, y\) zugehörige rechte und linke Eigenvektoren 
    \[ Ax = \lambda x, y^H A = \lambda y^H. \]

    Dann hat die Matrix \( A + \epsilon E \) für \(\epsilon\) hinreichend 
    klein einen einfachen Eigenwert \( \lambda(\epsilon) \), so dass 
    \[ \lambda(\epsilon) = \lambda + \epsilon \frac{y^H E x}{y^H x} + \mathcal{O}(\epsilon^2). \]
\end{karte}

\begin{karte}{Rayleigh-Quotient}
    Zu gegebener Matrix \(A\) und \(x \neq 0\) heißt 
    \[ \varrho_A(x) = \frac{x^H A x}{x^H x} \]
    Rayleigh-Quotient von \(x\).

    Die Menge 
    \[ \mathcal{F}(A) = \set{\varrho_A(x) : x\in \C^n, x\neq 0} \]
    aller Rayleigh-Quotienten heißt der Wertebereich von \(A\).
    Auch für reelle Matrizen wird der Wertebereich über \(\C^n\) gebildet.
\end{karte}

\begin{karte}{Rayleigh-Quotient Eigenschaften}
    Es gilt 
    \begin{enumerate}
        \item \( \varrho(\gamma x) = \varrho(x) \) für alle \(\gamma \neq 0, \gamma \in \C\).
        \item \( \lambda(A) \subset \mathcal{F}(A) \), d. h. alle Eigenwerte liegen im Wertebereich.
        \item Für normale Matrizen gilt \( \mathcal{F}(A) = \conv(\lambda(A)) \).
    \end{enumerate}
\end{karte}

\begin{karte}{Rayleigh-Ritz}
    Ist \( A\in \C^{n,n} \) hermitesch, dann gilt 
    \begin{enumerate}
        \item \( \lambda_{\min} \leq \varrho(x) \leq \lambda_{\max} \),
        \item \(\lambda_{\max} = \max_{x\neq 0} \varrho(x) \), 
        \item \( \lambda_{\min} = \min_{x\neq 0} \varrho(x) \).
    \end{enumerate}
\end{karte}

\begin{karte}{Bendixon-Hirsch}
    Für \( A\in \C^{n,n} \) gelte für \( \mu_n \leq \mu_1 \) und 
    \( \tau_n \leq \tau_1 \) 
    \[ \lambda \left( \frac{1}{2} (A + A^H) \right) \subset [\mu_n, \mu_1] \quad \text{und} 
    \quad \lambda \left( \frac{1}{2i} (A - A^H) \right) \subset [\tau_n, \tau_1]. \]

    Dann ist \( \mathcal{F}(A) \subset [\mu_n, \mu_1] \times i[\tau_n, \tau_1] \).
\end{karte}

\subsection{Potenzenmethode}

\begin{karte}{Konvergenzgeschwindigkeit Potenzenmethode}
    Es sei \( A\in \C^{n,n} \) diagonalisierbar mit \( X^{-1} A X = \Lambda = \diag(\lambda_1, \ldots, \lambda_n), 
    X = [x_1 \cdots x_n], ||x_i|| = 1 \) und es gelte 
    \[ \eta := \frac{\abs{\lambda_2}}{\abs{\lambda_1}} < 1. \]
    Ist für \( a := X^{-1}y_0, a = [\alpha_1 \cdots \alpha_n]^T \) die erste Komponente \( \alpha_1 \neq 0 \), 
    dann gilt für \( y_{k+1} = A y_k \):
    \begin{enumerate}
        \item \( y_k = \lambda_1^k [\alpha_1 x_1 + \mathcal{O}(\eta^k)] \) (\(y_k/\lambda_1^k\) konvergiert 
        gegen einen Eigenvektor von \(A\)).
        \item Für die Rayleigh-Quotienten gilt \( \varrho_A(y_k) = \lambda_1 + \mathcal{O}(\eta^k) \).
        \item Falls \(A\) normal ist, gilt \( \varrho_A(y_k) = \lambda_1 + \mathcal{O}(\eta^{2k}) \).
    \end{enumerate}
\end{karte}

\begin{karte}{Potenzenmethode}
    \begin{tabbing}
        \(y_0 \neq 0\) gegebener Startvektor, \(y_0 = y_0 / ||y_0||\) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> \( z_{k+1} = A y_k \) \\
        \> \( \varrho_k = y_k^H z_{k+1} \) \\
        \> \( y_{k+1} = \frac{1}{||z_{k+1}||} z_{k+1}\) \\
        end for
    \end{tabbing}
    Methode ist langsam, wenn \( \eta \) nahe bei eins ist. 
    Man kann außerdem nur den betragsgrößten Eingenwert und zugehörigen 
    Eigenvektor berechnen. 
\end{karte}

\begin{karte}{Inverse Potenzenmethode mit Shift}
    \begin{tabbing}
        \( \mu \in \C \) gegebener Shift, \(y_0 \neq 0\) gegebener Startvektor, \(y_0 = y_0 / ||y_0||\) \\
        Berechne die LR-Zerlegung von \( \mu I - A \)\\
        for \= \( k = 0,1,\ldots \) do \\
        \> Löse \( (\mu I - A) z_{k+1} = y_k \) mit der LR-Zerlegung \\
        \> \( y_{k+1} = \frac{1}{||z_{k+1}||} z_{k+1}\) \\
        \> \( \varrho_{k+1} = \varrho_A(y_{k+1}) = y_{k+1}^H A y_{k+1} \) \\
        end for
    \end{tabbing}
\end{karte}

\begin{karte}{Rayleigh-Quotienten Iteration}
    \begin{tabbing}
        \( \mu_0 \in \C \) gegebener Shift, \(y_0 \neq 0\) gegebener Startvektor, \(y_0 = y_0 / ||y_0||\) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> Löse \( (\mu_k I - A) z_{k+1} = y_k \) \\
        \> \( y_{k+1} = \frac{1}{||z_{k+1}||} z_{k+1}\) \\
        \> \( \mu_{k+1} = \varrho_A(y_{k+1}) = y_{k+1}^H A y_{k+1} \) \\
        end for
    \end{tabbing}
    
    Ist \(A\) normal, dann konvergiert die Folge \( (\mu_k)_k \) der Rayleigh-Quotienten Iteration 
    lokal kubisch gegen einen Eigenwert von \(A\), d. h., wenn die Folge \(y_k\) gegen einen Eigenvektor 
    konvergiert, dann konvergiert \(\mu_k\) gegen den zugehörigen Eigenwert.
\end{karte}

\subsection{QR-Algorithmus}

\begin{karte}{Iterative Berechnung der Eigenwerte}
    Sei \( u_1 \) der Eigenvektor zum betragsgrößten Eigenwert, 
    \( \mathcal{S}_1 = u_1^\bot = \set{u \in \C^n \;|\; u_1^H u = 0} \)
    sowie \( P_1 \) der Orthogonalprojektor \( P_1 = I - u_1 u_1^H \) auf \( \mathcal{S}_1 \).
    
    Ist \( U^H A U = R = D + N \) die Schurform von \(A\) und \( A_1 := P_1 A \), 
    dann ist \( U^H A_1 U =\left[ \begin{matrix}
        0 & \\
        & I
    \end{matrix}\right] R \) die Schurform von \(A_1\). 
    Insbesondere hat \( A_1 \) die Eigenwerte \( 0, \lambda_2,\ldots, \lambda_n \).
\end{karte}

\begin{karte}{Simultane Iteration}
    \begin{tabbing}
        \( U_0 \in \C^{n,m} \) unitär, \(U_0^H U_0 = I_m, A_0 = A\) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> Setze \( Y_{k+1} = A U_k \) \\
        \> Berechne die QR-Zerlegung \( Y_{k+1} = U_{k+1} R_{k+1} \) \\
        \> \( A_{k+1} = U_{k+1}^H A U_{k+1} \) \\
        end for
    \end{tabbing}
\end{karte}

\begin{karte}{Simultane Iteration Konvergenz}
    Sei \( A = X \Lambda X^{-1} \) diagonalisierbar, alle Eigenwerte von \(A\) 
    paarweise betragsmäßig verschieden und alle Hauptuntermatrizen von \( X \)
    (\(X_{1:j, 1:j}\)) nicht singulär. Dann konvergiert die Folge \( (A_k)_k = U_k^H A U_k \)
    mit \( U_k \) aus dem Algorithmus der simultanen Iteration, \( U_0 = I \), 
    gegen die Schurform von \(A\), 
    \[ U_k^H A U_k \rightarrow R, \quad \diag(R) = \diag(\lambda_1, \ldots, \lambda_n). \]
\end{karte}

\begin{karte}{QR-Algorithmus}
    \begin{tabbing}
        \( A_0 = A \) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> Berechne die QR-Zerlegung \( A_k = Q_k R_k \) \\
        \> Setze \( A_{k+1} = R_k Q_k \) \\
        end for
    \end{tabbing}
    Sollte in dieser Form nicht angewendet werden, 
    da untere Nebendiagonalelemente der Schurform mit 
    Konvergenzfaktor \( \eta_m = \abs{\lambda_{m+1} / \lambda_m} \)
    gegen Null konvergieren. Wenn \( \eta_m \approx 1 \), ist dies sehr langsam.
\end{karte}

\begin{karte}{QR-Algorithmus mit Shifts}
    \begin{tabbing}
        \( A_0 = A \) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> Wähle einen Shift \(\mu_k\) \\
        \> Berechne die QR-Zerlegung \( A_k - \mu_k I = Q_k R_k \) \\
        \> Setze \( A_{k+1} = R_k Q_k + \mu_k I \) \\
        end for
    \end{tabbing}
\end{karte}

\begin{karte}{QR-Algorithmus mit mehrfachen Shifts}
    Shiftpolynome \[ f_k(\lambda) = \prod_{i=1}^r (\lambda - \mu_i^{(k)}). \]
    Ein Mehrfachshift vom Grad \(r\) ist äquivalent zu einer Folge von \(r\) 
    Mehrfachshifts vom Grad 1.
    \begin{tabbing}
        \( A_0 = A \) \\
        for \= \( k = 0,1,\ldots \) do \\
        \> Wähle ein Shiftpolynom \(f_k\) \\
        \> Berechne die QR-Zerlegung \( f(A_k) = Q_k R_k \) \\
        \> Setze \( A_{k+1} = Q_k^H A_k Q_k \) \\
        end for
    \end{tabbing}
\end{karte}

\begin{karte}{Eigenschaften Mehrfachshifts}
    Für den QR-Algorithmus mit mehrfachen Shifts gilt 
    \begin{align*}
        A_k &= U_k^H A U_k, &U_k = Q_0 \cdots Q_{k-1}, \\
        p_k(A) &= \prod_{i=0}^k f_i(A) = U_{k+1} T_{k+1}, &T_{k+1} = R_k \cdots R_0.
    \end{align*}
\end{karte}

\subsection{Effiziente Implementierung}

\begin{karte}{Householder-Matrix}
    Für \( u\in \C^n \) mit \( ||u|| = 1 \) heißt die 
    hermitesche und unitäre Matrix \( P = I - 2 u u^H \in \C^{n,n} \) 
    Householder-Matrix. \(u\) kann so gewählt werden, dass für ein gegebenes 
    \( x\in \C^n, x\neq 0 \)
    \[ Px = \alpha e_1, \alpha \in \C \]
    gilt, wobei 
    \[ \abs{\alpha} = ||x||, \quad u = \frac{x-\alpha e_1}{||x-\alpha e_1||}. \]
\end{karte}

\begin{karte}{Obere Hessenberg-Form}
    Jede Matrix \(A\in \C^{n,n}\) kann durch \(n-2\) Householder-Transformationen 
    auf obere Hessenberg-Form transformiert werden 
    \[ U^H A U = H = \left[ \begin{matrix}
        h_{11} & \cdots & h_{1,n-1} & h_{1,n} \\
        h_{21} & \ddots & \vdots & \vdots \\
        & \ddots & h_{n-1, n-1} & h_{n-1,n} \\
        0 & & h_{n,n-1} & h_{n,n}
    \end{matrix} \right], U = U_1 \cdots U_{n-2} \]
    mit Housholder-Matrizen \(U_1, \ldots, U_{n-2}\). 

    Der Aufwand für die Transformation beträgt bei einer allgemeinen Matrix 
    \(\frac{10}{3} n^3\) und bei einer hermiteschen Matrix \( \frac{4}{3}n^3 \)
    komplexe Operationen.
\end{karte}

\begin{karte}{QR-Zerlegung Hessenberg-Matrix}
    Es sei \(H\) eine obere Hessenberg-Matrix und 
    \[ H = QR, \quad \tilde{H} = RQ. \]
    Dann ist \(\tilde{H}\) ebenfalls eine obere Hessenberg-Matrix.

    Die Berechnung der QR-Zerlegung einer oberen Hessenberg-Matrix 
    kostet nur \( \mathcal{O}(n^2) \) Operationen statt \(\mathcal{O}(n^3)\) 
    bei einer voll besetzten Matrix.
\end{karte}

\begin{karte}{Deflation}
    Verschwindet während des Algorithmus ein Nebendiagonalelement von 
    \(H_k\), dann hat \(H_k\) die Form 
    \[ H_k = \left[ \begin{matrix}
        H_{11} & H_{12} \\ 0 & H_{22}
    \end{matrix} \right], H_{11} \in \C^{p,p}, 1\leq p < n. \]
    Das Poblem zerfällt in zwei kleinere Teilprobleme. 
    Man spricht dann auch von \textit{Deflation}.
\end{karte}

\begin{karte}{Hessenberg mit Shift}
    Es sei \(\mu\) ein Eigenwert einer unredizierten oberen Hessenberg-Matrix \(H\).
    Ist \(H - \mu I = QR\) die QR-Zerlegung der geshifteten Matrix und \( \tilde{H} = RQ + \mu I \), 
    dann gilt \( \tilde{h}_{n,n-1} = 0 \) und \( \tilde{h}_{n,n} = \mu \).
\end{karte}

\begin{karte}{Wilkinson-Shifts}
    \( \mu \) wird als derjenige Eigenwert von 
    \[ \left[ \begin{matrix}
        h_{n-1,n-1} & h_{n-1,n} \\ h_{n,n-1} & h_{n,n}
    \end{matrix} \right] \] 
    gewählt, der näher an \(h_{n,n} \) liegt. Ist \(H\) hermitesch, 
    also tridiagonal, lässt sich der Wilkinson-Shift durch 
    \[ \mu_k = h_{n,n} + d - \sign(d) \sqrt{d^2 + (h_{n-1,n})^2} \]
    berechnen, wobei \( d = (h_{n-1,n-1} - h_{n,n})/2 \) ist.
\end{karte}

\begin{karte}{Komplexe Shifts}
    Ist \(A\) und damit auch die Hessenberg-Matrix \(H\) 
    nicht symmetrisch und reell, kann \(A\) Paare konjugiert komplexer 
    Eigenwerte haben. Hier bieten sich Mehrfachshifts an, bei denen ein konjugiert 
    komplexes Paar von Shifts verwendet wird. Dadurch lässt sich komplexe Arithmetik 
    vermeiden.
\end{karte}

\begin{karte}{Implizites Q-Theorem}
    Seien \( Q = [q_1 \cdots q_n] \) und \(U = [u_1 \cdots u_n]\) 
    unitäre Matrizen, für die 
    \[ Q^H A Q = H \quad \text{und} \quad U^H A U = G \] 
    obere Hessenberg-Form haben. 
    Ist \( u_1 = q_1 \) und \(H\) unrediziert, dann gilt 
    \( Q = UD \) mit einer unitären Diagonalmatrix \(D\) und 
    \( \abs{h_{j,j-1}} = \abs{g_{j,j-1}} \) für \( j= 2,\ldots, n \).

    Man kann um \( A_{k+1} = Q_k^H A_k Q_k \) aus \(A_k\) 
    im QR-Algorithmus mit einfachem Shift \(\mu_k\) zu berechnen 
    lediglich 
    \begin{enumerate}
        \item die erste Spalte von \( Q_k \) (die der normierten ersten Spalte von \(A_k - \mu_k I\) entspricht) 
        berechnen muss und 
        \item die übrigen Spalten von \( Q_k \) so wählt, dass \(Q_k\) unitär ist und \( A_{k+1} \) eine unredizierte obere Hessenberg-Matrix ist.
    \end{enumerate}
    Dies wird beim \textit{bulge chasing} verwendet.
\end{karte}

\subsection{Singulärwertzerlegung}

\begin{karte}{Obere Bidiagonalform}
    Zu \( A\in \C^{m,n} \) mit \( m\geq n \) existieren unitäre 
    Matrizen \( P, Q \) mit 
    \[ PAQ = \left[ \begin{matrix}
        B \\ 0
    \end{matrix} \right], \qquad B = \left[ \begin{matrix}
        d_1 & f_1 & 0 \cdots & 0 \\
        0 & d_2 & \ddots & \ddots & \vdots \\
        \vdots & \ddots & \ddots & \ddots & 0 \\
        \vdots & & \ddots & \ddots & f_{n-1} \\
        0 & \cdots & \cdots & 0 & d_n
    \end{matrix} \right]. \]
    Dies lässt sich über geeignete Householder-Transformationen erreichen.
\end{karte}

\begin{karte}{Bidiagonalisierung von \(A\in \C^{m,n}\)}
    \begin{tabbing}
        { \texttt{function house}\((x)\) liefert \(u\) mit \((I - 2 u u^H)x = \alpha e_1\)} \\
        for \= \( j = 1,\ldots,n \) do \\
        \> \(u = \texttt{house}(A_{j:m, j})\) \\
        \> if \= \(j \leq n-2\) then \\
        \> \> \(u = \texttt{house}(A_{j,j+1:n}^T)\) \\
        \> \> \( A-{j:m, j+1:n} = A_{j:m,j+1:n}(I_{n-j} - 2 u u^H) \) \\
        \> end if \\
        end for
    \end{tabbing}
\end{karte}

\begin{karte}{Golub-Kahan Schritt zur Singulärwertzerlegung}
    \begin{tabbing}
        Gegeben sei Bidiagonalmatrix \(A \in \C^{m,n}\) \\
        Zu gegebenem Shift \(\mu\) berechne erste Spalte von \(A^H A - \mu I: t = \left[ \begin{matrix}
            \abs{a_{11}}^2 - \mu \\ a_{11} \overline{a_{12}}
        \end{matrix} \right]\) \\
        for \= \( j = 1 ,\ldots,n-1 \) do \\
        \> \(u = \texttt{house}(t)\) \\
        \> \( \tilde{j} = \max\{1, j-1\} \) \\
        \> \( A_{\tilde{j}:j+1, j:j+1} = A_{\tilde{j}:j+1, j:j+1}(I - 2 u u^H) \) \\
        \> \( u = \texttt{house}(A_{j:j+1, j}) \) \\
        \> \( \tilde{j} = \min\{j+2, n\} \) \\
        \> \( A_{j:j+1, j:\tilde{j}} = (I - 2 u u^H) A_{j:j+1, j:\tilde{j}} \) \\
        \> if \=\(j < n-1\) then \\
        \> \> \( t = A_{j,j+1:j+2}^T \) \\
        \> end if \\
        end for
    \end{tabbing}
\end{karte}

\subsection{Trägheit, Bisektionsverfahren}

\begin{karte}{Kongruenztransformation}
    Für \( A\in \C^{n,n} \) und eine nicht singuläre Matrix \(T\in \C^{n,n}\) 
    heißt die Abbildung \( A \mapsto T^H A T \) eine \textit{Kongruenztransformation}. 
    \(A\) und \( T^H A T \) werden kongruent genannt.
\end{karte}

\begin{karte}{Trägheit}
    Für \( A\in \C^{n,n} \) hermitesch heißt das Triple \( in(A) = (\pi, \nu, \delta) \) 
    der Anzahl der positiven, negativen und Eigenwerten gleich Null von \(A\) 
    die \textit{Trägheit} (inertia) von \(A\).

    Sei \(A\) hermitesch und \(T\) nicht singulär. Dann haben \(A\) und \(T^H A T\) 
    dieselbe Trägheit.
\end{karte}

\begin{karte}{Tridiagonales Spektrum Slicing}
    Die Werte \(d_j\), die in Gleitkommaarithmetik mit dem Tridiagonales Spektrum Slicing Algorithmus 
    berechnet werden, haben dieselben Vorzeichen wie die Werte \( \widehat{d}_j \), 
    die in exakter Arithmetik ausgehend von einer Tridiagonalmatrix \(\widehat{A}\) 
    berechnet werden, wobei 
    \[ \widehat{\alpha}_j = \alpha_j, \qquad \abs{\widehat{\beta}_j} = \abs{\beta_j}(1+\epsilon_j), 
    \abs{\epsilon_j} \leq 2.5\epsilon + \mathcal{O}(\epsilon^2). \]
\end{karte}